{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to call for Speed Dating Experiment Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: CLEANING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to drop data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropData(main_df, remove_df): \n",
    "    main_df = main_df.drop(remove_df.index)  #removing old values\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to insert missing data to new df (fill in NaN values with 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to replace any NaN values with 0 where desired (takes in series; returns series)\n",
    "def fillNaN(feature, df):\n",
    "    df[feature] = df[feature].replace([np.nan], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for feature SETS: remove old values and replace with cleaned values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanDF(main_df, df_all_feature_null, feature):\n",
    "    atr_nan = main_df[main_df[feature].isnull()] #look where partner did not rate subject on feature\n",
    "    atr_cleaned = atr_nan.drop(df_all_feature_null.index) #returning just rows with NaN data in feature but have other columns with data\n",
    "    #amt = len(atr_cleaned) #test\n",
    "    fillNaN([feature], atr_cleaned)  ##calling function fillNaN to replace NaN values with 0\n",
    "    main_df = main_df.drop(atr_cleaned.index)  #removing old values\n",
    "    main_df = pd.concat([main_df, atr_cleaned]) #adding cleaned data back into df\n",
    "    return main_df\n",
    "\n",
    "    \n",
    "#main_df\n",
    "#df_all_feature_null = all atr_o_NaN or all atr_NaN\n",
    "#feature = looking for NaN values of this attribute\n",
    "##atr_nan = df that holds 1 attribute with NaN values\n",
    "##atr_cleaned = df that holds values where feature in question has NaN value but other attributes have ratings \n",
    "    #e.g. looking at attr_o; atr_fillNaN = rows that have NaN values for attr_o but have values for intel_o, since_o...etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to remove old NaN values and replace with new dataset of '0' values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanFeatDF(feature, main_df, cleaned_df): #clean feature subDF\n",
    "    cleaned_df[feature] = cleaned_df[feature].replace([np.nan], 0)\n",
    "    main_df = main_df.drop(cleaned_df.index)  #removing old values\n",
    "    main_df = pd.concat([main_df, cleaned_df]) #adding cleaned data back into df\n",
    "    return main_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to recount 'round' (AKA 'met_count')\n",
    "\n",
    "Changes the value in 'round' to the number of people the person met with; takes into account subjects who's columns were dropped for bad data (i.e. if subject and partner didn't score each other than can assume they both didn't meet; e.g. value in 'match_ave' would be off since they met with less people than it's averaging a number out of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recountMET(df):\n",
    "    for iid in df.iid.unique():\n",
    "        iidsubset = df[df.iid == iid]\n",
    "        val = len(iidsubset)\n",
    "        df.loc[df.iid == iid, 'round'] = [val]*val  #add it to a column in the original dataframe, not the iidsubset one -- for where the iid is equal to the one being calculated in your loop (hence the loc[] business)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to check if lengths of dropna() values are the same**\n",
    "\n",
    "If return 'FALSE':  all values are present or all are missing (i.e. subject didn't answer that question).\n",
    "If return 'TRUE':  there are rows of data that are missng a value for the feature; e.g. person didn't want to rate low for other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkMissing (feature1, feature2, df):\n",
    "    if (len(df[feature1].dropna())) != (len(df[feature2].dropna())):\n",
    "        print True\n",
    "    else:\n",
    "        print False\n",
    "\n",
    "        \n",
    "        \n",
    "        #UNCESSISARY LIKE THIS; better to iterate through \n",
    "        \n",
    "        \n",
    "        #checkAllMissing (df, feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: CONDENSE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def renameFeature(feature, new_feature_name, df):\n",
    "    df.rename(columns={feature: new_feature_name}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def renameFeatures(feature_key, new_feature_key, df):\n",
    "    columns = df.columns\n",
    "    new_columns = [row.replace(feature_key,new_feature_key) for row in columns]\n",
    "    df.rename(columns=dict(zip(columns, new_columns)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Compress Features Within Dataset to Get Averages & Sums***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Sums:\n",
    "\n",
    "Takes in a series (feature) & dataframe; Returns a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSum(feature, df):\n",
    "    list = []\n",
    "    for iid in df.iid.unique():\n",
    "        iidsubset = df[df.iid == iid]\n",
    "        if (iidsubset[feature].isnull().all()) == False: \n",
    "            sum = iidsubset[feature].sum()\n",
    "            list.append(sum)\n",
    "        else: \n",
    "            list.append(np.NaN)\n",
    "    return pd.Series(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Get Averages of a Feature Set:\n",
    "\n",
    "Takes in a series (feature) & dataframe; Returns a series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to return **average score**:  \n",
    "(take sum of values and divide by met_count)\n",
    "\n",
    "*use when each row of data for the feature is different (within a subject's data)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAveScore(feature, df):\n",
    "    list = []\n",
    "    for iid in df.iid.unique():\n",
    "        iidsubset = df[df.iid == iid]\n",
    "        if (iidsubset[feature].isnull().all()) == False:\n",
    "            denom = iidsubset['met_count'].unique()[0]\n",
    "            sum = iidsubset[feature].sum()\n",
    "            divis = sum/denom\n",
    "            list.append(divis)\n",
    "        else: \n",
    "            list.append(np.NaN)\n",
    "    return pd.Series(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#EXAMPLE\n",
    "\n",
    "#df_female_raw[['iid', 'attr_o', 'met_count']]\n",
    "#get average scores of 'attr_o' for each iid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to return **average of 1 rating / met_count** \n",
    "\n",
    "*use when each row of data for the feature is the same (within a subject's data)* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAve(feature, df):\n",
    "    list = []\n",
    "    for iid in df.iid.unique():\n",
    "        iidsubset = df[df.iid == iid]\n",
    "        if (iidsubset[feature].isnull().all()) == False:\n",
    "            denom = iidsubset['met_count'].unique()[0] #returning 1 instance met_count\n",
    "            nom = iidsubset[feature].unique()[0]  #returning 1 instance of the feature\n",
    "            divis = nom/denom\n",
    "            list.append(divis)\n",
    "        else: \n",
    "            list.append(np.NaN)\n",
    "    return pd.Series(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EXAMPLE\n",
    "\n",
    "#df_female_raw[['iid', 'match_es', 'met_count']]\n",
    "#want to get average of match_es (match_es/met_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to return expnum_ave (out of 20 people) and exphappy_ave (out of 10 pts):\n",
    "\n",
    "Function takes in a feature, a value, and a dataframe and returns a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expAve(feature, denom, df):\n",
    "    list = []\n",
    "    for iid in df.iid.unique():\n",
    "        iidsubset = df[df.iid == iid]\n",
    "        if (iidsubset[feature].isnull().all()) == False:\n",
    "            f = iidsubset[feature].unique()[0]\n",
    "            ave = f / denom\n",
    "            list.append(ave)\n",
    "        else:\n",
    "            list.append(np.NaN)\n",
    "    return pd.Series(list)\n",
    "\n",
    "#EXPNUM_AVE (/20ppl)\n",
    "\n",
    "#EXPHAPPY_AVE  (out of/10PTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Grab 1 Value of Feature Data for Each iid:\n",
    "Takes in a series (feature) & dataframe; Returns a series\n",
    "\n",
    "For features that have one consistent number for each person's iid #  (only want to return one instance of that number per iid #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getValueSet(feature, df):\n",
    "    list = []\n",
    "    for iid in df.iid.unique():\n",
    "        iidsubset = df[df.iid == iid]\n",
    "        if (iidsubset[feature].isnull().all()) == False:\n",
    "            denom = len(iidsubset)\n",
    "            sum = iidsubset[feature].sum()\n",
    "            divis = sum/denom\n",
    "            list.append(divis)\n",
    "        else:\n",
    "            list.append(np.NaN)\n",
    "    return pd.Series(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "#getValueSet('met_count', df_female_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Convert Values from Old DF to New Condensed DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvertDF(DF, df):  #DF = old dataframe    #df = new data frame\n",
    "    df['iid'] = DF.iid.unique()  #returning iid# (1 unique value per person - 1 row per subject)\n",
    "    df['gender'] = getValueSet('gender', DF) #returning 1 row per iid with subject's gender\n",
    "    df['age'] = getValueSet('age', DF) #returning 1 row per iid with subject's age\n",
    "    df['met_count'] = getValueSet('met_count', DF) #returning 1 row per iid with met_count info (how many people each person met with)\n",
    "    df['exphappy'] = getValueSet('exphappy', DF) #returning rating for exphappy per iid \n",
    "    df['expnum'] = getValueSet('expnum', DF) #returning expnum per iid (1 value)\n",
    "    df['match_es'] = getValueSet('match_es', DF) \n",
    "    \n",
    "    df['attr_iMeasUp_1'] = getValueSet('attr_iMeasUp_1', DF)\n",
    "    df['sinc_iMeasUp_1'] = getValueSet('sinc_iMeasUp_1', DF)\n",
    "    df['intel_iMeasUp_1'] = getValueSet('intel_iMeasUp_1', DF)\n",
    "    df['fun_iMeasUp_1'] = getValueSet('fun_iMeasUp_1', DF)\n",
    "    df['amb_iMeasUp_1']= getValueSet('amb_iMeasUp_1', DF)\n",
    "    \n",
    "    df['attr_iMeasUp_2'] = getValueSet('attr_iMeasUp_2', DF)\n",
    "    df['sinc_iMeasUp_2'] = getValueSet('sinc_iMeasUp_2', DF)\n",
    "    df['intel_iMeasUp_2'] = getValueSet('intel_iMeasUp_2', DF)\n",
    "    df['fun_iMeasUp_2'] = getValueSet('fun_iMeasUp_2', DF)\n",
    "    df['amb_iMeasUp_2']= getValueSet('amb_iMeasUp_2', DF)\n",
    "    \n",
    "    df['attr_oPercveMe_1'] = getValueSet('attr_oPercveMe_1', DF)\n",
    "    df['sinc_oPercveMe_1'] = getValueSet('sinc_oPercveMe_1', DF)\n",
    "    df['intel_oPercveMe_1'] = getValueSet('intel_oPercveMe_1', DF)\n",
    "    df['fun_oPercveMe_1'] = getValueSet('fun_oPercveMe_1', DF)\n",
    "    df['amb_oPercveMe_1'] = getValueSet('amb_oPercveMe_1', DF)\n",
    "    \n",
    "    df['attr_oPercveMe_2'] = getValueSet('attr_oPercveMe_2', DF)\n",
    "    df['sinc_oPercveMe_2'] = getValueSet('sinc_oPercveMe_2', DF)\n",
    "    df['intel_oPercveMe_2'] = getValueSet('intel_oPercveMe_2', DF)\n",
    "    df['fun_oPercveMe_2'] = getValueSet('fun_oPercveMe_2', DF)\n",
    "    df['amb_oPercveMe_2'] = getValueSet('amb_oPercveMe_2', DF)\n",
    "    \n",
    "    df['attr_iRateMe_exp'] = getValueSet('attr_iRateMe_exp', DF)\n",
    "    df['attr_iRateMe_exp'] = getValueSet('attr_iRateMe_exp', DF)\n",
    "    df['intel_iRateMe_exp'] = getValueSet('intel_iRateMe_exp', DF)\n",
    "    df['fun_iRateMe_exp'] = getValueSet('fun_iRateMe_exp', DF)\n",
    "    df['amb_iRateMe_exp'] = getValueSet('amb_iRateMe_exp', DF)\n",
    "    \n",
    "    df['match_sum'] = getSum('match', DF)\n",
    "    df['dec_sum'] = getSum('dec', DF) #sum of subject's decisions (num of 'yes'')\n",
    "    df['dec_o_sum'] = getSum('dec_o', DF) #sum of parnter's decisions (num of 'yes'')\n",
    "    \n",
    "    df['match_es_ave'] = getAve('match_es', DF)  #MATCH_ES_AVE  = % of people they think they'll match with\n",
    "    df['like_ave'] = getAveScore('like', DF)  #LIKE_AVE ##?\n",
    "    df['like_o_ave'] = getAveScore('like_o', DF)  #LIKE_O_AVE ##?\n",
    "    df['prob_ave'] = getAveScore('prob', DF)  #PROB_AVE ##?\n",
    "    df['prob_o_ave'] = getAveScore('prob_o', DF)  #PROB_O_AVE ##?\n",
    "       \n",
    "    df['dec_ave'] = getAveScore('dec', DF)  #DEC_AVE (average decision of subject to want to date)\n",
    "    df['dec_o_ave'] = getAveScore('dec_o', DF)  #DEC_AVE (average dec of partners to want to date subject)\n",
    "    df['match_ave'] = getAveScore('match', DF) #MATCH_AVE (average match count/#of people met with)\n",
    "    \n",
    "    df['expnum_ave'] = expAve('expnum', 20, df)\n",
    "    df['exphappy_ave'] = expAve('exphappy', 10, df)\n",
    "    \n",
    "    df['attr_ave'] = getAveScore('attr', DF) \n",
    "    df['sinc_ave'] = getAveScore('sinc', DF)  \n",
    "    df['intel_ave'] = getAveScore('intel', DF) \n",
    "    df['fun_ave'] = getAveScore('fun', DF) \n",
    "    df['amb_ave'] = getAveScore('amb',  DF) \n",
    "    df['shar_ave'] = getAveScore('shar', DF) \n",
    "    \n",
    "    df['attr_o_ave'] = getAveScore('attr_o', DF) \n",
    "    df['sinc_o_ave'] = getAveScore('sinc_o', DF)  \n",
    "    df['intel_o_ave'] = getAveScore('intel_o', DF) \n",
    "    df['fun_o_ave'] = getAveScore('fun_o', DF) \n",
    "    df['amb_o_ave'] = getAveScore('amb_o', DF) \n",
    "    df['shar_o_ave'] = getAveScore('shar_o', DF) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
